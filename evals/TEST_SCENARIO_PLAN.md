# HR DSS í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ê³„íšì„œ (Day 1-5)

> ì‘ì„±ì¼: 2026-01-21 | ë²„ì „: 1.0

---

## ëª©ì°¨

1. [í…ŒìŠ¤íŠ¸ ì „ëµ ê°œìš”](#1-í…ŒìŠ¤íŠ¸-ì „ëµ-ê°œìš”)
2. [Day 1 í…ŒìŠ¤íŠ¸: P0-P1 ë¬¸ì„œ ê²€ì¦](#2-day-1-í…ŒìŠ¤íŠ¸-p0-p1-ë¬¸ì„œ-ê²€ì¦)
3. [Day 2 í…ŒìŠ¤íŠ¸: P2 Data Readiness](#3-day-2-í…ŒìŠ¤íŠ¸-p2-data-readiness)
4. [Day 3 í…ŒìŠ¤íŠ¸: P3-P4 Ontology/KG](#4-day-3-í…ŒìŠ¤íŠ¸-p3-p4-ontologykg)
5. [Day 4 í…ŒìŠ¤íŠ¸: P5 Agent ì—”ì§„](#5-day-4-í…ŒìŠ¤íŠ¸-p5-agent-ì—”ì§„)
6. [Day 5 í…ŒìŠ¤íŠ¸: P6-P7 Workflow + í‰ê°€](#6-day-5-í…ŒìŠ¤íŠ¸-p6-p7-workflow--í‰ê°€)
7. [í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤](#7-í†µí•©-í…ŒìŠ¤íŠ¸-ì‹œë‚˜ë¦¬ì˜¤)
8. [í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³  í…œí”Œë¦¿](#8-í…ŒìŠ¤íŠ¸-ê²°ê³¼-ë³´ê³ -í…œí”Œë¦¿)

---

## 1. í…ŒìŠ¤íŠ¸ ì „ëµ ê°œìš”

### 1.1 í…ŒìŠ¤íŠ¸ ë ˆë²¨

| ë ˆë²¨ | ë²”ìœ„ | ë„êµ¬ | ìë™í™” |
|------|------|------|--------|
| Unit Test | ê°œë³„ í•¨ìˆ˜/ë©”ì„œë“œ | pytest | âœ… |
| Integration Test | ëª¨ë“ˆ ê°„ ì—°ë™ | pytest + Neo4j | âœ… |
| E2E Test | ì „ì²´ í”Œë¡œìš° | Scenario-based | ìˆ˜ë™ |
| Acceptance Test | AC ê¸°ì¤€ ê²€ì¦ | Custom Eval | âœ… |

### 1.2 Acceptance Criteria (AC) ë§¤í•‘

| AC ID | ê¸°ì¤€ | í…ŒìŠ¤íŠ¸ Day | ëª©í‘œ |
|-------|------|-----------|------|
| AC-1 | 4ëŒ€ ìœ ìŠ¤ì¼€ì´ìŠ¤ ì‘ë‹µ | Day 4-5 | 100% |
| AC-2 | 3ì•ˆ ë¹„êµ ìƒì„± | Day 4 | 100% |
| AC-3 | ê·¼ê±° ì—°ê²°ë¥  | Day 4-5 | â‰¥ 95% |
| AC-4 | í™˜ê°ë¥  | Day 4-5 | â‰¤ 5% |
| AC-5 | KG ì—”í„°í‹° ì»¤ë²„ë¦¬ì§€ | Day 3 | 100% |
| AC-6 | HITL ì›Œí¬í”Œë¡œ | Day 5 | ë™ì‘ |

### 1.3 í…ŒìŠ¤íŠ¸ í™˜ê²½

```yaml
environments:
  local:
    neo4j: "bolt://localhost:7687"
    python: "3.11+"
    pytest: "8.3+"

  ci:
    neo4j: "neo4j-aura-test"
    runner: "GitHub Actions"
```

---

## 2. Day 1 í…ŒìŠ¤íŠ¸: P0-P1 ë¬¸ì„œ ê²€ì¦

### 2.1 í…ŒìŠ¤íŠ¸ ëª©ì 

P0 Kick-offì™€ P1 Key Questions ë‹¨ê³„ì˜ ì‚°ì¶œë¬¼ ì™„ì„±ë„ ê²€ì¦

### 2.2 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### TS-D1-01: PoC Charter ì™„ì„±ë„ ê²€ì¦

```yaml
scenario_id: TS-D1-01
name: "PoC Charter ì™„ì„±ë„ ê²€ì¦"
category: Documentation
priority: P0

preconditions:
  - docs/specs/poc-charter.md íŒŒì¼ ì¡´ì¬

test_cases:
  - id: TC-D1-01-01
    name: "í•„ìˆ˜ ì„¹ì…˜ ì¡´ì¬ í™•ì¸"
    check:
      - "[ ] ëª©ì  (Purpose) ì„¹ì…˜ ì¡´ì¬"
      - "[ ] ë²”ìœ„ (Scope) ì„¹ì…˜ ì¡´ì¬"
      - "[ ] ì¼ì • (Timeline) ì„¹ì…˜ ì¡´ì¬"
      - "[ ] íŒ€ êµ¬ì„± (Team) ì„¹ì…˜ ì¡´ì¬"
      - "[ ] ì„±ê³µ ê¸°ì¤€ (Success Criteria) ì„¹ì…˜ ì¡´ì¬"
    expected: "ëª¨ë“  í•„ìˆ˜ ì„¹ì…˜ ì¡´ì¬"

  - id: TC-D1-01-02
    name: "ë§ˆì¼ìŠ¤í†¤ ì •ì˜ í™•ì¸"
    check:
      - "[ ] M1~M7 ë§ˆì¼ìŠ¤í†¤ ì •ì˜"
      - "[ ] ê° ë§ˆì¼ìŠ¤í†¤ì— ë‚ ì§œ ì§€ì •"
      - "[ ] ê²€ì¦ ê¸°ì¤€ ëª…ì‹œ"
    expected: "7ê°œ ë§ˆì¼ìŠ¤í†¤ ì™„ì „ ì •ì˜"
```

#### TS-D1-02: Question Set ê²€ì¦

```yaml
scenario_id: TS-D1-02
name: "Question Set êµ¬ì¡° ê²€ì¦"
category: Documentation
priority: P0

test_cases:
  - id: TC-D1-02-01
    name: "4ëŒ€ ìœ ìŠ¤ì¼€ì´ìŠ¤ ì •ì˜ í™•ì¸"
    check:
      - "[ ] A-1: 12ì£¼ Capacity ë³‘ëª© ì˜ˆì¸¡"
      - "[ ] B-1: Go/No-go + ì„±ê³µí™•ë¥ "
      - "[ ] C-1: ì¦ì› ì›ì¸ë¶„í•´"
      - "[ ] D-1: ì—­ëŸ‰ íˆ¬ì ROI"
    expected: "4ê°œ ìœ ìŠ¤ì¼€ì´ìŠ¤ ëª¨ë‘ ì •ì˜"

  - id: TC-D1-02-02
    name: "3ë‹¨ê³„ ëŒ€í™” í…œí”Œë¦¿ í™•ì¸"
    check:
      - "[ ] 1ë‹¨ê³„: ë¬¸ì œ ì •ì˜ (DecisionCase)"
      - "[ ] 2ë‹¨ê³„: ëŒ€ì•ˆ íƒìƒ‰ (Option ë¹„êµ)"
      - "[ ] 3ë‹¨ê³„: ë³´ê³ /ê¸°íš (Action + Workflow)"
    expected: "ê° ìœ ìŠ¤ì¼€ì´ìŠ¤ì— 3ë‹¨ê³„ í…œí”Œë¦¿ ì ìš©"

  - id: TC-D1-02-03
    name: "ì…ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜ í™•ì¸"
    check:
      - "[ ] Input YAML ìŠ¤í‚¤ë§ˆ ì •ì˜"
      - "[ ] Output YAML ìŠ¤í‚¤ë§ˆ ì •ì˜"
      - "[ ] JSON ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜"
    expected: "ëª¨ë“  ìŠ¤í‚¤ë§ˆ í˜•ì‹ ì •ì˜ ì™„ë£Œ"
```

#### TS-D1-03: Decision Criteria ê²€ì¦

```yaml
scenario_id: TS-D1-03
name: "Decision Criteria ì™„ì„±ë„"
category: Documentation
priority: P0

test_cases:
  - id: TC-D1-03-01
    name: "ì˜í–¥ë„/ì„±ê³µí™•ë¥  ì‚°ì • ê¸°ì¤€"
    check:
      - "[ ] ì˜í–¥ë„ ê³„ì‚° ê³µì‹ ì •ì˜"
      - "[ ] ì„±ê³µí™•ë¥  ê³„ì‚° ìš”ì†Œ ì •ì˜"
      - "[ ] ë¦¬ìŠ¤í¬ ë ˆë²¨ ê¸°ì¤€ ì •ì˜"
    expected: "ì •ëŸ‰ì  ê³„ì‚° ê¸°ì¤€ ì™„ë¹„"
```

### 2.3 Day 1 ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | ê²€ì¦ ë°©ë²• | Pass ê¸°ì¤€ |
|------|----------|----------|
| PoC Charter v1 | ìˆ˜ë™ ê²€í†  | í•„ìˆ˜ ì„¹ì…˜ 100% |
| Question Set v1 | ìŠ¤í‚¤ë§ˆ ê²€ì¦ | 4ê°œ UC ì •ì˜ |
| Decision Criteria | ìˆ˜ë™ ê²€í†  | ê³„ì‚° ê¸°ì¤€ ëª…ì‹œ |
| KPI & AC | ìˆ˜ë™ ê²€í†  | 6ê°œ AC ì •ì˜ |

---

## 3. Day 2 í…ŒìŠ¤íŠ¸: P2 Data Readiness

### 3.1 í…ŒìŠ¤íŠ¸ ëª©ì 

Mock ë°ì´í„° 6ì¢…ì˜ í’ˆì§ˆê³¼ ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê²€ì¦

### 3.2 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### TS-D2-01: Mock ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦

```yaml
scenario_id: TS-D2-01
name: "Mock ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦"
category: Data Quality
priority: P0

test_cases:
  - id: TC-D2-01-01
    name: "persons.json ìŠ¤í‚¤ë§ˆ ê²€ì¦"
    file: "data/mock/persons.json"
    schema_check:
      required_fields:
        - employeeId: "string (EMP-XXXXXX)"
        - name: "string"
        - orgUnitId: "string (ORG-XXXX)"
        - positionId: "string (POS-XXX)"
        - hireDate: "date (YYYY-MM-DD)"
      count_check: ">= 50"
    expected: "65ëª… ë°ì´í„°, ìŠ¤í‚¤ë§ˆ ì¼ì¹˜"

  - id: TC-D2-01-02
    name: "projects.json ìŠ¤í‚¤ë§ˆ ê²€ì¦"
    file: "data/mock/projects.json"
    schema_check:
      required_fields:
        - projectId: "string (PRJ-XXX)"
        - name: "string"
        - status: "enum (ACTIVE, COMPLETED, PLANNED)"
        - startDate: "date"
        - endDate: "date"
      count_check: ">= 10"
    expected: "12ê°œ í”„ë¡œì íŠ¸, 30ê°œ WP"

  - id: TC-D2-01-03
    name: "skills.json ìŠ¤í‚¤ë§ˆ ê²€ì¦"
    file: "data/mock/skills.json"
    schema_check:
      required_fields:
        - competencyId: "string (CMP-XXX)"
        - name: "string"
        - category: "string"
        - level: "number (1-5)"
    expected: "40ê°œ ì—­ëŸ‰, 50ê°œ ì¦ê±°"

  - id: TC-D2-01-04
    name: "orgs.json ìŠ¤í‚¤ë§ˆ ê²€ì¦"
    file: "data/mock/orgs.json"
    schema_check:
      required_fields:
        - orgUnitId: "string (ORG-XXXX)"
        - name: "string"
        - parentId: "string | null"
        - headcount: "number"
    expected: "20ê°œ ì¡°ì§"

  - id: TC-D2-01-05
    name: "opportunities.json ìŠ¤í‚¤ë§ˆ ê²€ì¦"
    file: "data/mock/opportunities.json"
    schema_check:
      required_fields:
        - opportunityId: "string (OPP-XXX)"
        - name: "string"
        - dealValue: "number"
        - stage: "enum"
        - probability: "number (0-1)"
    expected: "15ê°œ ê¸°íšŒ"

  - id: TC-D2-01-06
    name: "assignments.json ìŠ¤í‚¤ë§ˆ ê²€ì¦"
    file: "data/mock/assignments.json"
    schema_check:
      required_fields:
        - assignmentId: "string (ASN-XXX)"
        - employeeId: "string"
        - projectId: "string"
        - allocationFTE: "number (0-1)"
    expected: "42ê°œ ë°°ì¹˜, 30ê°œ ê°€ìš©ì„±"
```

#### TS-D2-02: Join Key ì—°ê²°ì„± ê²€ì¦

```yaml
scenario_id: TS-D2-02
name: "Join Key ì—°ê²°ì„± ê²€ì¦"
category: Data Quality
priority: P0

test_cases:
  - id: TC-D2-02-01
    name: "employeeId ì—°ê²° ê²€ì¦"
    description: "persons.employeeIdê°€ assignments, skillsì—ì„œ ì°¸ì¡° ê°€ëŠ¥"
    check_query: |
      SELECT p.employeeId
      FROM persons p
      LEFT JOIN assignments a ON p.employeeId = a.employeeId
      WHERE a.employeeId IS NULL
    expected: "ê³ ì•„ ë ˆì½”ë“œ 0ê±´"

  - id: TC-D2-02-02
    name: "orgUnitId ì—°ê²° ê²€ì¦"
    description: "orgs.orgUnitIdê°€ personsì—ì„œ ì°¸ì¡° ê°€ëŠ¥"
    expected: "ëª¨ë“  persons.orgUnitIdê°€ orgsì— ì¡´ì¬"

  - id: TC-D2-02-03
    name: "projectId ì—°ê²° ê²€ì¦"
    description: "projects.projectIdê°€ assignmentsì—ì„œ ì°¸ì¡° ê°€ëŠ¥"
    expected: "ëª¨ë“  assignments.projectIdê°€ projectsì— ì¡´ì¬"
```

#### TS-D2-03: Data Quality ì§€í‘œ ê²€ì¦

```yaml
scenario_id: TS-D2-03
name: "Data Quality ì§€í‘œ ê²€ì¦"
category: Data Quality
priority: P0

test_cases:
  - id: TC-D2-03-01
    name: "ê²°ì¸¡ë¥  ê²€ì¦"
    metric: "missing_rate"
    target: "< 10%"
    check_all_files: true

  - id: TC-D2-03-02
    name: "ì¤‘ë³µë¥  ê²€ì¦"
    metric: "duplicate_rate"
    target: "< 1%"
    check_all_files: true

  - id: TC-D2-03-03
    name: "í‚¤ ë§¤ì¹­ë¥  ê²€ì¦"
    metric: "key_match_rate"
    target: "> 95%"

  - id: TC-D2-03-04
    name: "í•„ìˆ˜í•„ë“œ ì¶©ì¡±ë¥  ê²€ì¦"
    metric: "required_field_rate"
    target: "> 80%"
```

### 3.3 Day 2 pytest êµ¬í˜„

```python
# tests/test_day2_data_readiness.py

import pytest
import json
from pathlib import Path

DATA_DIR = Path("data/mock")

class TestMockDataSchema:
    """TS-D2-01: Mock ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦"""

    @pytest.fixture
    def persons_data(self):
        with open(DATA_DIR / "persons.json") as f:
            return json.load(f)

    def test_persons_count(self, persons_data):
        """TC-D2-01-01: persons ë°ì´í„° ìˆ˜ëŸ‰"""
        employees = persons_data.get("employees", [])
        assert len(employees) >= 50, f"Expected >= 50, got {len(employees)}"

    def test_persons_required_fields(self, persons_data):
        """TC-D2-01-01: persons í•„ìˆ˜ í•„ë“œ"""
        required = ["employeeId", "name", "orgUnitId", "positionId"]
        for emp in persons_data.get("employees", []):
            for field in required:
                assert field in emp, f"Missing field: {field}"

    def test_persons_id_format(self, persons_data):
        """TC-D2-01-01: employeeId í˜•ì‹ ê²€ì¦"""
        import re
        pattern = re.compile(r"^EMP-\d{6}$")
        for emp in persons_data.get("employees", []):
            assert pattern.match(emp["employeeId"]), f"Invalid ID: {emp['employeeId']}"


class TestJoinKeyIntegrity:
    """TS-D2-02: Join Key ì—°ê²°ì„± ê²€ì¦"""

    @pytest.fixture
    def all_data(self):
        data = {}
        for f in DATA_DIR.glob("*.json"):
            with open(f) as file:
                data[f.stem] = json.load(file)
        return data

    def test_employee_org_link(self, all_data):
        """TC-D2-02-02: employeeId â†’ orgUnitId ì—°ê²°"""
        org_ids = {o["orgUnitId"] for o in all_data["orgs"].get("orgUnits", [])}
        for emp in all_data["persons"].get("employees", []):
            assert emp["orgUnitId"] in org_ids, f"Orphan orgUnitId: {emp['orgUnitId']}"


class TestDataQualityMetrics:
    """TS-D2-03: Data Quality ì§€í‘œ ê²€ì¦"""

    def test_missing_rate(self):
        """TC-D2-03-01: ê²°ì¸¡ë¥  < 10%"""
        # Implementation
        pass

    def test_duplicate_rate(self):
        """TC-D2-03-02: ì¤‘ë³µë¥  < 1%"""
        # Implementation
        pass
```

### 3.4 Day 2 ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | ê²€ì¦ ë°©ë²• | Pass ê¸°ì¤€ |
|------|----------|----------|
| persons.json | pytest | 65ëª…, ìŠ¤í‚¤ë§ˆ ì¼ì¹˜ |
| projects.json | pytest | 12ê°œ, WP 30ê°œ |
| skills.json | pytest | 40ê°œ ì—­ëŸ‰ |
| orgs.json | pytest | 20ê°œ ì¡°ì§ |
| opportunities.json | pytest | 15ê°œ ê¸°íšŒ |
| assignments.json | pytest | 42ê°œ ë°°ì¹˜ |
| Join Key ì—°ê²° | pytest | 95%+ ë§¤ì¹­ |
| Data Quality Score | Dashboard | 100% READY |

---

## 4. Day 3 í…ŒìŠ¤íŠ¸: P3-P4 Ontology/KG

### 4.1 í…ŒìŠ¤íŠ¸ ëª©ì 

Neo4j Knowledge Graph êµ¬ì¶• ì™„ì„±ë„ì™€ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

### 4.2 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### TS-D3-01: Neo4j ìŠ¤í‚¤ë§ˆ ê²€ì¦

```yaml
scenario_id: TS-D3-01
name: "Neo4j ìŠ¤í‚¤ë§ˆ ê²€ì¦"
category: KG
priority: P0

test_cases:
  - id: TC-D3-01-01
    name: "ë…¸ë“œ íƒ€ì… ì¡´ì¬ í™•ì¸ (47ê°œ)"
    cypher: |
      CALL db.labels() YIELD label
      RETURN count(label) as nodeTypeCount
    expected: ">= 47"

  - id: TC-D3-01-02
    name: "í•„ìˆ˜ ë…¸ë“œ íƒ€ì… í™•ì¸"
    cypher: |
      CALL db.labels() YIELD label
      WHERE label IN ['Employee', 'OrgUnit', 'Project', 'Competency',
                      'Assignment', 'Opportunity', 'DecisionCase', 'Option',
                      'Finding', 'Evidence', 'Model', 'ForecastPoint']
      RETURN collect(label) as labels
    expected: "12ê°œ í•„ìˆ˜ ë…¸ë“œ ëª¨ë‘ ì¡´ì¬"

  - id: TC-D3-01-03
    name: "ê´€ê³„ íƒ€ì… ì¡´ì¬ í™•ì¸"
    cypher: |
      CALL db.relationshipTypes() YIELD relationshipType
      RETURN count(relationshipType) as relTypeCount
    expected: ">= 50"

  - id: TC-D3-01-04
    name: "í•„ìˆ˜ ê´€ê³„ íƒ€ì… í™•ì¸"
    cypher: |
      CALL db.relationshipTypes() YIELD relationshipType
      WHERE relationshipType IN ['BELONGS_TO', 'ASSIGNED_TO', 'HAS_COMPETENCY',
                                  'REQUIRES_ROLE', 'HAS_SIGNAL', 'HAS_EVIDENCE',
                                  'PRODUCED_BY', 'AFFECTS', 'LEADS_TO']
      RETURN collect(relationshipType) as relTypes
    expected: "9ê°œ í•„ìˆ˜ ê´€ê³„ ëª¨ë‘ ì¡´ì¬"
```

#### TS-D3-02: ë°ì´í„° ì ì¬ ê²€ì¦

```yaml
scenario_id: TS-D3-02
name: "ë°ì´í„° ì ì¬ ê²€ì¦"
category: KG
priority: P0

test_cases:
  - id: TC-D3-02-01
    name: "Employee ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (e:Employee) RETURN count(e) as cnt"
    expected: ">= 65"

  - id: TC-D3-02-02
    name: "OrgUnit ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (o:OrgUnit) RETURN count(o) as cnt"
    expected: ">= 20"

  - id: TC-D3-02-03
    name: "Project ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (p:Project) RETURN count(p) as cnt"
    expected: ">= 12"

  - id: TC-D3-02-04
    name: "Competency ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (c:Competency) RETURN count(c) as cnt"
    expected: ">= 40"

  - id: TC-D3-02-05
    name: "Opportunity ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (o:Opportunity) RETURN count(o) as cnt"
    expected: ">= 15"

  - id: TC-D3-02-06
    name: "DecisionCase ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (d:DecisionCase) RETURN count(d) as cnt"
    expected: ">= 4"

  - id: TC-D3-02-07
    name: "Option ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (o:Option) RETURN count(o) as cnt"
    expected: ">= 8"

  - id: TC-D3-02-08
    name: "Finding ë…¸ë“œ ìˆ˜ëŸ‰"
    cypher: "MATCH (f:Finding) RETURN count(f) as cnt"
    expected: ">= 6"
```

#### TS-D3-03: KG ë¬´ê²°ì„± ê²€ì¦

```yaml
scenario_id: TS-D3-03
name: "KG ë¬´ê²°ì„± ê²€ì¦"
category: KG
priority: P0

test_cases:
  - id: TC-D3-03-01
    name: "ê³ ì•„ ë…¸ë“œ ê²€ì¶œ"
    cypher: |
      MATCH (n)
      WHERE NOT (n)--()
      RETURN labels(n) as type, count(n) as orphanCount
    expected: "orphanCount = 0 for all types"

  - id: TC-D3-03-02
    name: "ì¤‘ë³µ ID ê²€ì¶œ"
    cypher: |
      MATCH (n)
      WHERE n.id IS NOT NULL
      WITH n.id as id, count(*) as cnt
      WHERE cnt > 1
      RETURN id, cnt
    expected: "ê²°ê³¼ 0ê±´"

  - id: TC-D3-03-03
    name: "Employee-OrgUnit ì—°ê²°"
    cypher: |
      MATCH (e:Employee)
      WHERE NOT (e)-[:BELONGS_TO]->(:OrgUnit)
      RETURN count(e) as unlinkedCount
    expected: "unlinkedCount = 0"

  - id: TC-D3-03-04
    name: "Finding-Evidence ì—°ê²°"
    cypher: |
      MATCH (f:Finding)
      WHERE NOT (f)-[:HAS_EVIDENCE]->(:Evidence)
      RETURN count(f) as unevidencedCount
    expected: "unevidencedCount = 0"
```

#### TS-D3-04: KG ì¿¼ë¦¬ ì„±ëŠ¥ ê²€ì¦

```yaml
scenario_id: TS-D3-04
name: "KG ì¿¼ë¦¬ ì„±ëŠ¥ ê²€ì¦"
category: KG
priority: P1

test_cases:
  - id: TC-D3-04-01
    name: "ê°€ë™ë¥  ì¡°íšŒ ì¿¼ë¦¬"
    cypher: |
      MATCH (o:OrgUnit {orgUnitId: 'ORG-0011'})<-[:BELONGS_TO]-(e:Employee)
      MATCH (e)-[a:ASSIGNED_TO]->(p:Project)
      MATCH (a)-[:FOR_BUCKET]->(tb:TimeBucket)
      WHERE tb.weekNumber >= 4 AND tb.weekNumber <= 16
      RETURN tb.bucketId, sum(a.allocationFTE) as totalFTE
      ORDER BY tb.weekNumber
    expected_time: "< 500ms"

  - id: TC-D3-04-02
    name: "ì—­ëŸ‰ ê°­ ì¡°íšŒ ì¿¼ë¦¬"
    cypher: |
      MATCH (c:Competency {category: 'AI/ML'})<-[ce:HAS_EVIDENCE]-(e:Employee)
      WHERE ce.level >= 4
      RETURN c.name, count(e) as expertCount
    expected_time: "< 500ms"

  - id: TC-D3-04-03
    name: "ì˜ì‚¬ê²°ì • ì¶”ì  ì¿¼ë¦¬"
    cypher: |
      MATCH (dc:DecisionCase)-[:HAS_OPTION]->(opt:Option)
      MATCH (opt)-[:EVALUATED_BY]->(eval:Evaluation)
      MATCH (dc)-[:HAS_FINDING]->(f:Finding)-[:HAS_EVIDENCE]->(ev:Evidence)
      WHERE dc.caseId = 'DC-001'
      RETURN dc, opt, eval, f, ev
    expected_time: "< 1000ms"
```

### 4.3 Day 3 pytest êµ¬í˜„

```python
# tests/test_day3_kg.py

import pytest
from neo4j import GraphDatabase

class TestKGSchema:
    """TS-D3-01: Neo4j ìŠ¤í‚¤ë§ˆ ê²€ì¦"""

    @pytest.fixture(scope="class")
    def driver(self):
        driver = GraphDatabase.driver(
            "bolt://localhost:7687",
            auth=("neo4j", "password")
        )
        yield driver
        driver.close()

    def test_node_type_count(self, driver):
        """TC-D3-01-01: ë…¸ë“œ íƒ€ì… 47ê°œ ì´ìƒ"""
        with driver.session() as session:
            result = session.run("CALL db.labels() YIELD label RETURN count(label) as cnt")
            count = result.single()["cnt"]
            assert count >= 47, f"Expected >= 47 node types, got {count}"

    def test_required_node_types(self, driver):
        """TC-D3-01-02: í•„ìˆ˜ ë…¸ë“œ íƒ€ì… ì¡´ì¬"""
        required = ['Employee', 'OrgUnit', 'Project', 'Competency',
                    'Assignment', 'Opportunity', 'DecisionCase', 'Option']
        with driver.session() as session:
            result = session.run("CALL db.labels() YIELD label RETURN collect(label) as labels")
            labels = result.single()["labels"]
            for node_type in required:
                assert node_type in labels, f"Missing node type: {node_type}"


class TestKGIntegrity:
    """TS-D3-03: KG ë¬´ê²°ì„± ê²€ì¦"""

    def test_no_orphan_nodes(self, driver):
        """TC-D3-03-01: ê³ ì•„ ë…¸ë“œ 0ê±´"""
        with driver.session() as session:
            result = session.run("""
                MATCH (n)
                WHERE NOT (n)--()
                RETURN count(n) as orphanCount
            """)
            count = result.single()["orphanCount"]
            assert count == 0, f"Found {count} orphan nodes"

    def test_no_duplicate_ids(self, driver):
        """TC-D3-03-02: ì¤‘ë³µ ID 0ê±´"""
        with driver.session() as session:
            result = session.run("""
                MATCH (n)
                WHERE n.id IS NOT NULL
                WITH n.id as id, count(*) as cnt
                WHERE cnt > 1
                RETURN count(id) as duplicateCount
            """)
            count = result.single()["duplicateCount"]
            assert count == 0, f"Found {count} duplicate IDs"
```

### 4.4 Day 3 ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | ê²€ì¦ ë°©ë²• | Pass ê¸°ì¤€ |
|------|----------|----------|
| ë…¸ë“œ íƒ€ì… ìˆ˜ | Cypher | â‰¥ 47ê°œ |
| ê´€ê³„ íƒ€ì… ìˆ˜ | Cypher | â‰¥ 50ê°œ |
| Employee ë…¸ë“œ | Cypher | â‰¥ 65ê°œ |
| ê³ ì•„ ë…¸ë“œ | Cypher | 0ê°œ |
| ì¤‘ë³µ ID | Cypher | 0ê±´ |
| ì¿¼ë¦¬ ì„±ëŠ¥ | Benchmark | < 500ms |
| AC-5 (ì»¤ë²„ë¦¬ì§€) | Dashboard | 100% |

---

## 5. Day 4 í…ŒìŠ¤íŠ¸: P5 Agent ì—”ì§„

### 5.1 í…ŒìŠ¤íŠ¸ ëª©ì 

6ê°œ ì„œë¸Œì—ì´ì „íŠ¸ì˜ ê¸°ëŠ¥ ë° ì¶œë ¥ í˜•ì‹ ê²€ì¦

### 5.2 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### TS-D4-01: Query Decomposition Agent

```yaml
scenario_id: TS-D4-01
name: "Query Decomposition Agent ê²€ì¦"
category: Agent
priority: P0

test_cases:
  - id: TC-D4-01-01
    name: "A-1 ì§ˆë¬¸ ë¶„í•´"
    input:
      question: "í–¥í›„ 12ì£¼ê°„ ë³¸ë¶€/íŒ€ë³„ ê°€ë™ë¥  90% ì´ˆê³¼ ì£¼ì°¨ì™€ ë³‘ëª© ì›ì¸ì„ ì˜ˆì¸¡í•´ì¤˜"
    expected_output:
      type: "CAPACITY_FORECAST"
      scope:
        horizon: 12
        unit: "WEEK"
      objective:
        metricType: "UTILIZATION"
        targetValue: 0.9
    assertions:
      - "output.type == 'CAPACITY_FORECAST'"
      - "output.scope.horizon == 12"
      - "'UTILIZATION' in output.objective.metricType"

  - id: TC-D4-01-02
    name: "B-1 ì§ˆë¬¸ ë¶„í•´"
    input:
      question: "'100ì–µ ë¯¸ë””ì–´ AX' í”„ë¡œì íŠ¸ ë‚´ë¶€ ìˆ˜í–‰ ê°€ëŠ¥ ì—¬ë¶€ì™€ ì„±ê³µí™•ë¥ "
    expected_output:
      type: "GO_NOGO"
      scope:
        opportunity: "100ì–µ ë¯¸ë””ì–´ AX"
    assertions:
      - "output.type == 'GO_NOGO'"
      - "'ë¯¸ë””ì–´' in output.scope.opportunity"

  - id: TC-D4-01-03
    name: "C-1 ì§ˆë¬¸ ë¶„í•´"
    input:
      question: "ë°ì´í„°í”Œë«í¼íŒ€ 1ëª… ì¦ì› ìš”ì²­ì˜ ì›ì¸ë¶„í•´"
    expected_output:
      type: "HEADCOUNT_ANALYSIS"
    assertions:
      - "output.type == 'HEADCOUNT_ANALYSIS'"
      - "output.scope.requestedHeadcount >= 1"

  - id: TC-D4-01-04
    name: "D-1 ì§ˆë¬¸ ë¶„í•´"
    input:
      question: "AI-driven ì „í™˜ ê´€ì ì—ì„œ ì—­ëŸ‰ ê°­ Top10 ì •ëŸ‰í™”"
    expected_output:
      type: "COMPETENCY_GAP"
    assertions:
      - "output.type == 'COMPETENCY_GAP'"
      - "'AI' in str(output.scope)"
```

#### TS-D4-02: Option Generator Agent

```yaml
scenario_id: TS-D4-02
name: "Option Generator Agent ê²€ì¦"
category: Agent
priority: P0

test_cases:
  - id: TC-D4-02-01
    name: "3ì•ˆ ìƒì„± í™•ì¸"
    input:
      decision_case:
        type: "GO_NOGO"
        opportunity: "100ì–µ ë¯¸ë””ì–´ AX"
    expected_output:
      option_count: 3
      option_types: ["CONSERVATIVE", "BALANCED", "AGGRESSIVE"]
    assertions:
      - "len(output.options) == 3"
      - "all(opt.option_type in ['CONSERVATIVE', 'BALANCED', 'AGGRESSIVE'] for opt in output.options)"

  - id: TC-D4-02-02
    name: "Option í•„ìˆ˜ í•„ë“œ"
    assertions:
      - "all('name' in opt for opt in output.options)"
      - "all('description' in opt for opt in output.options)"
      - "all('actions' in opt for opt in output.options)"
      - "all(len(opt['actions']) > 0 for opt in output.options)"

  - id: TC-D4-02-03
    name: "ì¶”ì²œ ì˜µì…˜ ì„ ì •"
    assertions:
      - "'recommendation' in output"
      - "output.recommendation in [opt.option_id for opt in output.options]"
```

#### TS-D4-03: Impact Simulator Agent

```yaml
scenario_id: TS-D4-03
name: "Impact Simulator Agent ê²€ì¦"
category: Agent
priority: P0

test_cases:
  - id: TC-D4-03-01
    name: "As-Is vs To-Be ë¹„êµ"
    input:
      option:
        option_id: "OPT-001"
        option_type: "BALANCED"
      baseline:
        utilization: 0.85
        headcount: 10
    expected_output:
      metrics:
        - type: "UTILIZATION"
        - type: "COST"
        - type: "TIME"
      comparison:
        as_is: {}
        to_be: {}
    assertions:
      - "'as_is' in output.comparison"
      - "'to_be' in output.comparison"
      - "len(output.metrics) >= 3"

  - id: TC-D4-03-02
    name: "ì‹œê³„ì—´ ì˜ˆì¸¡"
    assertions:
      - "'time_series' in output"
      - "len(output.time_series) > 0"
```

#### TS-D4-04: Success Probability Agent

```yaml
scenario_id: TS-D4-04
name: "Success Probability Agent ê²€ì¦"
category: Agent
priority: P0

test_cases:
  - id: TC-D4-04-01
    name: "ì„±ê³µí™•ë¥  ê³„ì‚°"
    input:
      option:
        option_id: "OPT-001"
        option_type: "BALANCED"
      context:
        resource_match: 0.7
        timeline_risk: 0.3
    expected_output:
      probability: "number (0-1)"
      confidence: "number (0-1)"
      factors: []
    assertions:
      - "0 <= output.probability <= 1"
      - "0 <= output.confidence <= 1"
      - "len(output.factors) > 0"

  - id: TC-D4-04-02
    name: "ì„±ê³µ ìš”ì¸ ë¶„í•´"
    assertions:
      - "all('name' in f for f in output.factors)"
      - "all('weight' in f for f in output.factors)"
      - "all('score' in f for f in output.factors)"
```

#### TS-D4-05: Validator Agent

```yaml
scenario_id: TS-D4-05
name: "Validator Agent ê²€ì¦"
category: Agent
priority: P0

test_cases:
  - id: TC-D4-05-01
    name: "ê·¼ê±° ì—°ê²° ê²€ì¦"
    input:
      response:
        claims:
          - text: "AIì†”ë£¨ì…˜íŒ€ ê°€ë™ë¥  90% ì´ˆê³¼"
            evidence:
              - source: "TMS"
                ref: "Assignment í…Œì´ë¸”"
          - text: "ê·¼ê±° ì—†ëŠ” ì£¼ì¥"
            evidence: null
    expected_output:
      evidence_coverage: 0.5
      hallucination_risk: 0.5
    assertions:
      - "output.evidence_coverage == 0.5"
      - "output.hallucination_risk >= 0.4"

  - id: TC-D4-05-02
    name: "í™˜ê° íƒì§€"
    input:
      response:
        claims:
          - text: "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í”„ë¡œì íŠ¸ PRJ-999"
            evidence: null
    assertions:
      - "output.hallucination_risk > 0.5"
      - "len(output.flagged_claims) > 0"
```

#### TS-D4-06: Workflow Builder Agent

```yaml
scenario_id: TS-D4-06
name: "Workflow Builder Agent ê²€ì¦"
category: Agent
priority: P0

test_cases:
  - id: TC-D4-06-01
    name: "8ë‹¨ê³„ ì›Œí¬í”Œë¡œ ìƒì„±"
    input:
      decision_case:
        type: "GO_NOGO"
    expected_output:
      workflow:
        steps: []
    assertions:
      - "len(output.workflow.steps) == 8"
      - "output.workflow.steps[0].type == 'QUERY_DECOMPOSITION'"
      - "output.workflow.steps[-1].type == 'WORKFLOW_GENERATION'"

  - id: TC-D4-06-02
    name: "HITL ì¤‘ë‹¨ì  í™•ì¸"
    assertions:
      - "any(step.hitl_gate for step in output.workflow.steps)"
```

### 5.3 Day 4 pytest êµ¬í˜„

```python
# tests/test_day4_agents.py

import pytest
from backend.agent_runtime.agents.query_decomposition import QueryDecompositionAgent
from backend.agent_runtime.agents.option_generator import OptionGeneratorAgent
from backend.agent_runtime.agents.impact_simulator import ImpactSimulatorAgent
from backend.agent_runtime.agents.success_probability import SuccessProbabilityAgent
from backend.agent_runtime.agents.validator import ValidatorAgent
from backend.agent_runtime.agents.workflow_builder import WorkflowBuilderAgent


class TestQueryDecomposition:
    """TS-D4-01: Query Decomposition Agent"""

    @pytest.fixture
    def agent(self):
        return QueryDecompositionAgent()

    def test_capacity_question(self, agent):
        """TC-D4-01-01: A-1 ì§ˆë¬¸ ë¶„í•´"""
        result = agent.decompose("í–¥í›„ 12ì£¼ê°„ ë³¸ë¶€/íŒ€ë³„ ê°€ë™ë¥  90% ì´ˆê³¼ ì£¼ì°¨ì™€ ë³‘ëª© ì›ì¸ì„ ì˜ˆì¸¡í•´ì¤˜")
        assert result.query_type.value == "CAPACITY_FORECAST"
        assert result.horizon == 12

    def test_go_nogo_question(self, agent):
        """TC-D4-01-02: B-1 ì§ˆë¬¸ ë¶„í•´"""
        result = agent.decompose("'100ì–µ ë¯¸ë””ì–´ AX' í”„ë¡œì íŠ¸ ë‚´ë¶€ ìˆ˜í–‰ ê°€ëŠ¥ ì—¬ë¶€ì™€ ì„±ê³µí™•ë¥ ")
        assert result.query_type.value == "GO_NOGO"

    def test_headcount_question(self, agent):
        """TC-D4-01-03: C-1 ì§ˆë¬¸ ë¶„í•´"""
        result = agent.decompose("ë°ì´í„°í”Œë«í¼íŒ€ 1ëª… ì¦ì› ìš”ì²­ì˜ ì›ì¸ë¶„í•´")
        assert result.query_type.value == "HEADCOUNT_ANALYSIS"

    def test_competency_question(self, agent):
        """TC-D4-01-04: D-1 ì§ˆë¬¸ ë¶„í•´"""
        result = agent.decompose("AI-driven ì „í™˜ ê´€ì ì—ì„œ ì—­ëŸ‰ ê°­ Top10 ì •ëŸ‰í™”")
        assert result.query_type.value == "COMPETENCY_GAP"


class TestOptionGenerator:
    """TS-D4-02: Option Generator Agent"""

    @pytest.fixture
    def agent(self):
        return OptionGeneratorAgent()

    def test_generates_three_options(self, agent):
        """TC-D4-02-01: 3ì•ˆ ìƒì„±"""
        context = {"opportunity": "100ì–µ ë¯¸ë””ì–´ AX"}
        result = agent.generate("GO_NOGO", context, {})
        assert len(result.options) == 3

    def test_option_types(self, agent):
        """TC-D4-02-01: ì˜µì…˜ íƒ€ì… ë‹¤ì–‘ì„±"""
        context = {"opportunity": "100ì–µ ë¯¸ë””ì–´ AX"}
        result = agent.generate("GO_NOGO", context, {})
        types = {opt.option_type.value for opt in result.options}
        assert types == {"CONSERVATIVE", "BALANCED", "AGGRESSIVE"}


class TestImpactSimulator:
    """TS-D4-03: Impact Simulator Agent"""

    @pytest.fixture
    def agent(self):
        return ImpactSimulatorAgent()

    def test_as_is_to_be_comparison(self, agent):
        """TC-D4-03-01: As-Is vs To-Be"""
        option = {"option_id": "OPT-001", "option_type": "BALANCED"}
        baseline = {"utilization": 0.85, "headcount": 10}
        result = agent.simulate("GO_NOGO", option, baseline, 12)

        assert hasattr(result, 'metrics')
        assert len(result.metrics) >= 3


class TestSuccessProbability:
    """TS-D4-04: Success Probability Agent"""

    @pytest.fixture
    def agent(self):
        return SuccessProbabilityAgent()

    def test_probability_range(self, agent):
        """TC-D4-04-01: í™•ë¥  ë²”ìœ„"""
        result = agent.calculate_probability(
            subject_type="OPTION",
            subject_id="OPT-001",
            subject_name="í…ŒìŠ¤íŠ¸ ì˜µì…˜",
            context={}
        )
        assert 0 <= result.probability <= 1
        assert 0 <= result.confidence <= 1


class TestValidator:
    """TS-D4-05: Validator Agent"""

    @pytest.fixture
    def agent(self):
        return ValidatorAgent()

    def test_evidence_coverage(self, agent):
        """TC-D4-05-01: ê·¼ê±° ì—°ê²°ë¥ """
        result = agent.validate(
            response_text="AIì†”ë£¨ì…˜íŒ€ ê°€ë™ë¥  90% ì´ˆê³¼ ì˜ˆìƒ",
            evidence_refs=[{"source": "TMS", "ref": "Assignment"}],
            kg_context={}
        )
        assert hasattr(result, 'evidence_coverage')
        assert 0 <= result.evidence_coverage <= 1


class TestWorkflowBuilder:
    """TS-D4-06: Workflow Builder Agent"""

    @pytest.fixture
    def agent(self):
        return WorkflowBuilderAgent()

    def test_workflow_steps(self, agent):
        """TC-D4-06-01: 8ë‹¨ê³„ ì›Œí¬í”Œë¡œ"""
        workflow = agent.create_workflow("GO_NOGO")
        assert len(workflow.steps) == 8
```

### 5.4 Day 4 ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | ê²€ì¦ ë°©ë²• | Pass ê¸°ì¤€ |
|------|----------|----------|
| Query Decomposition | pytest | 4ê°œ UC ë¶„í•´ ì„±ê³µ |
| Option Generator | pytest | 3ì•ˆ ìƒì„± |
| Impact Simulator | pytest | As-Is/To-Be ë¹„êµ |
| Success Probability | pytest | í™•ë¥  0-1 ë²”ìœ„ |
| Validator | pytest | ê·¼ê±° ì—°ê²° ê²€ì¦ |
| Workflow Builder | pytest | 8ë‹¨ê³„ ìƒì„± |
| AC-2 (3ì•ˆ ë¹„êµ) | E2E | 100% |

---

## 6. Day 5 í…ŒìŠ¤íŠ¸: P6-P7 Workflow + í‰ê°€

### 6.1 í…ŒìŠ¤íŠ¸ ëª©ì 

HITL ìŠ¹ì¸ ì›Œí¬í”Œë¡œì™€ í‰ê°€ ì‹œìŠ¤í…œ ë™ì‘ ê²€ì¦

### 6.2 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### TS-D5-01: HITL ìŠ¹ì¸ ì›Œí¬í”Œë¡œ

```yaml
scenario_id: TS-D5-01
name: "HITL ìŠ¹ì¸ ì›Œí¬í”Œë¡œ ê²€ì¦"
category: Workflow
priority: P0

test_cases:
  - id: TC-D5-01-01
    name: "ìŠ¹ì¸ ìš”ì²­ ìƒì„±"
    input:
      decision_case_id: "DC-001"
      selected_option: "OPT-002"
    expected_output:
      approval_request:
        status: "PENDING"
        required_level: "TEAM_LEAD | DIVISION | EXECUTIVE"
    assertions:
      - "output.approval_request.status == 'PENDING'"
      - "'required_level' in output.approval_request"

  - id: TC-D5-01-02
    name: "ìŠ¹ì¸ ë ˆë²¨ ê²°ì •"
    input:
      decision_type: "GO_NOGO"
      deal_value: 10_000_000_000  # 100ì–µ
    expected_output:
      required_level: "EXECUTIVE"
    assertions:
      - "output.required_level == 'EXECUTIVE'"  # 10ì–µ ì´ìƒ

  - id: TC-D5-01-03
    name: "ìŠ¹ì¸ ì²˜ë¦¬"
    input:
      approval_id: "APR-001"
      decision: "APPROVE"
      approver_id: "EMP-000001"
      comment: "ìŠ¹ì¸í•©ë‹ˆë‹¤"
    expected_output:
      status: "APPROVED"
      workflow_triggered: true
    assertions:
      - "output.status == 'APPROVED'"
      - "output.workflow_triggered == True"

  - id: TC-D5-01-04
    name: "ê±°ë¶€ ì²˜ë¦¬"
    input:
      approval_id: "APR-002"
      decision: "REJECT"
      reason: "ì˜ˆì‚° ì´ˆê³¼"
    expected_output:
      status: "REJECTED"
    assertions:
      - "output.status == 'REJECTED'"

  - id: TC-D5-01-05
    name: "ì—ìŠ¤ì»¬ë ˆì´ì…˜"
    input:
      approval_id: "APR-003"
      action: "ESCALATE"
      to_level: "EXECUTIVE"
    expected_output:
      status: "ESCALATED"
      new_level: "EXECUTIVE"
```

#### TS-D5-02: Decision Log ê²€ì¦

```yaml
scenario_id: TS-D5-02
name: "Decision Log ê²€ì¦"
category: Workflow
priority: P0

test_cases:
  - id: TC-D5-02-01
    name: "ì˜ì‚¬ê²°ì • ë¡œê·¸ ê¸°ë¡"
    input:
      decision_case_id: "DC-001"
      final_decision: "OPT-002"
      approver: "EMP-000001"
    expected_output:
      log_entry:
        decision_case_id: "DC-001"
        selected_option_id: "OPT-002"
        approver_id: "EMP-000001"
        timestamp: "datetime"
    assertions:
      - "'timestamp' in output.log_entry"
      - "'decision_case_id' in output.log_entry"

  - id: TC-D5-02-02
    name: "ê°ì‚¬ ì¶”ì "
    assertions:
      - "'audit_trail' in output"
      - "all('actor' in entry for entry in output.audit_trail)"
      - "all('action' in entry for entry in output.audit_trail)"
```

#### TS-D5-03: Agent í‰ê°€ ì§€í‘œ

```yaml
scenario_id: TS-D5-03
name: "Agent í‰ê°€ ì§€í‘œ ê²€ì¦"
category: Evaluation
priority: P0

test_cases:
  - id: TC-D5-03-01
    name: "ì™„ê²°ì„± ì¸¡ì •"
    metric: "completeness"
    calculation: |
      required_fields = ['type', 'options', 'recommendation', 'evidence']
      present_fields = count(field in response for field in required_fields)
      completeness = present_fields / len(required_fields)
    target: "> 0.9"

  - id: TC-D5-03-02
    name: "ê·¼ê±° ì—°ê²°ë¥  ì¸¡ì •"
    metric: "evidence_coverage"
    calculation: |
      evidenced_claims = count(claim with evidence)
      total_claims = count(all claims)
      coverage = evidenced_claims / total_claims
    target: "> 0.95"
    acceptance_criteria: "AC-3"

  - id: TC-D5-03-03
    name: "í™˜ê°ë¥  ì¸¡ì •"
    metric: "hallucination_rate"
    calculation: |
      unevidenced_claims = count(claims without evidence)
      total_claims = count(all claims)
      hallucination_rate = unevidenced_claims / total_claims
    target: "< 0.05"
    acceptance_criteria: "AC-4"

  - id: TC-D5-03-04
    name: "ì¬í˜„ì„± ì¸¡ì •"
    metric: "reproducibility"
    calculation: |
      # ë™ì¼ ì…ë ¥ìœ¼ë¡œ 5íšŒ ì‹¤í–‰
      results = [run(same_input) for _ in range(5)]
      consistency = count(identical_results) / 5
    target: "> 0.95"

  - id: TC-D5-03-05
    name: "ì‘ë‹µ ì‹œê°„ ì¸¡ì •"
    metric: "response_time"
    calculation: "end_time - start_time"
    target: "< 30s"
```

#### TS-D5-04: Ontology í‰ê°€ ì§€í‘œ

```yaml
scenario_id: TS-D5-04
name: "Ontology í‰ê°€ ì§€í‘œ ê²€ì¦"
category: Evaluation
priority: P0

test_cases:
  - id: TC-D5-04-01
    name: "ì—”í„°í‹° ì»¤ë²„ë¦¬ì§€"
    metric: "entity_coverage"
    cypher: |
      CALL db.labels() YIELD label
      WITH collect(label) as labels
      RETURN size([l IN labels WHERE l IN $required_labels]) / size($required_labels) as coverage
    target: "= 1.0"
    acceptance_criteria: "AC-5"

  - id: TC-D5-04-02
    name: "ë§í¬ìœ¨"
    metric: "link_rate"
    cypher: |
      MATCH (n)
      WITH count(n) as total
      MATCH (n) WHERE (n)--()
      WITH total, count(n) as linked
      RETURN toFloat(linked) / total as link_rate
    target: "> 0.95"

  - id: TC-D5-04-03
    name: "ì¤‘ë³µ/ì¶©ëŒë¥ "
    metric: "duplicate_rate"
    cypher: |
      MATCH (n)
      WHERE n.id IS NOT NULL
      WITH n.id as id, count(*) as cnt
      WHERE cnt > 1
      RETURN count(id) as duplicate_count
    target: "= 0"
```

### 6.3 Day 5 pytest êµ¬í˜„

```python
# tests/test_day5_workflow.py

import pytest
from datetime import datetime
from backend.agent_runtime.workflows.hitl_approval import (
    HITLApprovalManager,
    ApprovalLevel,
    ApprovalStatus,
    DecisionType
)


class TestHITLApproval:
    """TS-D5-01: HITL ìŠ¹ì¸ ì›Œí¬í”Œë¡œ"""

    @pytest.fixture
    def manager(self):
        return HITLApprovalManager()

    def test_create_approval_request(self, manager):
        """TC-D5-01-01: ìŠ¹ì¸ ìš”ì²­ ìƒì„±"""
        workflow_context = {
            "decision_case_id": "DC-001",
            "options": {"recommendation": "OPT-002"},
            "impact_analysis": {},
            "validation_result": {"hallucination_risk": 0.03}
        }
        request = manager.create_approval_request(
            decision_type=DecisionType.GO_NOGO,
            workflow_context=workflow_context
        )
        assert request.status == ApprovalStatus.PENDING

    def test_approval_level_determination(self, manager):
        """TC-D5-01-02: ìŠ¹ì¸ ë ˆë²¨ ê²°ì •"""
        context = {
            "opportunity": {"deal_value": 10_000_000_000}
        }
        level = manager._determine_approval_level(DecisionType.GO_NOGO, context)
        # 10ì–µ ì´ìƒì€ EXECUTIVE ë˜ëŠ” DIVISION
        assert level in [ApprovalLevel.EXECUTIVE, ApprovalLevel.DIVISION]

    def test_approve_request(self, manager):
        """TC-D5-01-03: ìŠ¹ì¸ ì²˜ë¦¬"""
        # Create request first
        workflow_context = {"decision_case_id": "DC-001", "options": {}}
        request = manager.create_approval_request(DecisionType.GO_NOGO, workflow_context)

        # Approve
        result = manager.process_approval(
            request_id=request.request_id,
            decision="approve",
            approver_id="EMP-000001",
            comment="ìŠ¹ì¸"
        )
        assert result.status == ApprovalStatus.APPROVED

    def test_reject_request(self, manager):
        """TC-D5-01-04: ê±°ë¶€ ì²˜ë¦¬"""
        workflow_context = {"decision_case_id": "DC-002", "options": {}}
        request = manager.create_approval_request(DecisionType.GO_NOGO, workflow_context)

        result = manager.process_approval(
            request_id=request.request_id,
            decision="reject",
            approver_id="EMP-000001",
            comment="ì˜ˆì‚° ì´ˆê³¼"
        )
        assert result.status == ApprovalStatus.REJECTED


class TestDecisionLog:
    """TS-D5-02: Decision Log"""

    @pytest.fixture
    def manager(self):
        return HITLApprovalManager()

    def test_log_creation(self, manager):
        """TC-D5-02-01: ë¡œê·¸ ê¸°ë¡"""
        logs = manager.get_decision_logs(limit=10)
        # ë¡œê·¸ ì¡°íšŒ ê°€ëŠ¥ í™•ì¸
        assert isinstance(logs, list)


class TestAgentEvalMetrics:
    """TS-D5-03: Agent í‰ê°€ ì§€í‘œ"""

    def test_completeness_calculation(self):
        """TC-D5-03-01: ì™„ê²°ì„±"""
        response = {
            "type": "GO_NOGO",
            "options": [],
            "recommendation": "OPT-001",
            "evidence": []
        }
        required = ["type", "options", "recommendation", "evidence"]
        present = sum(1 for f in required if f in response)
        completeness = present / len(required)
        assert completeness > 0.9

    def test_evidence_coverage_target(self):
        """TC-D5-03-02: ê·¼ê±° ì—°ê²°ë¥  ëª©í‘œ"""
        # AC-3: >= 95%
        target = 0.95
        assert target >= 0.95

    def test_hallucination_rate_target(self):
        """TC-D5-03-03: í™˜ê°ë¥  ëª©í‘œ"""
        # AC-4: <= 5%
        target = 0.05
        assert target <= 0.05
```

### 6.4 Day 5 ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | ê²€ì¦ ë°©ë²• | Pass ê¸°ì¤€ |
|------|----------|----------|
| ìŠ¹ì¸ ìš”ì²­ ìƒì„± | pytest | ìƒíƒœ PENDING |
| ìŠ¹ì¸ ë ˆë²¨ ê²°ì • | pytest | ê¸ˆì•¡ë³„ ìë™ ê²°ì • |
| ìŠ¹ì¸/ê±°ë¶€ ì²˜ë¦¬ | pytest | ìƒíƒœ ë³€ê²½ |
| Decision Log | pytest | ê¸°ë¡ ìƒì„± |
| ì™„ê²°ì„± ì§€í‘œ | Dashboard | > 90% |
| ê·¼ê±° ì—°ê²°ë¥  | Dashboard | > 95% (AC-3) |
| í™˜ê°ë¥  | Dashboard | < 5% (AC-4) |
| HITL ì›Œí¬í”Œë¡œ | E2E | ë™ì‘ (AC-6) |

---

## 7. í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### 7.1 E2E ì‹œë‚˜ë¦¬ì˜¤: A-1 ì§ˆë¬¸ ì „ì²´ í”Œë¡œìš°

```yaml
scenario_id: E2E-01
name: "A-1 ì§ˆë¬¸ ì „ì²´ í”Œë¡œìš°"
category: E2E
priority: P0

steps:
  - step: 1
    name: "ì§ˆë¬¸ ì…ë ¥"
    action: "ì‚¬ìš©ìê°€ A-1 ì§ˆë¬¸ ì…ë ¥"
    input: "í–¥í›„ 12ì£¼ê°„ ë³¸ë¶€/íŒ€ë³„ ê°€ë™ë¥  90% ì´ˆê³¼ ì£¼ì°¨ì™€ ë³‘ëª© ì›ì¸ì„ ì˜ˆì¸¡í•´ì¤˜"

  - step: 2
    name: "ì§ˆë¬¸ ë¶„í•´"
    agent: "QueryDecomposition"
    expected: "CAPACITY_FORECAST íƒ€ì…ìœ¼ë¡œ ë¶„í•´"

  - step: 3
    name: "KG ì¡°íšŒ"
    action: "Neo4jì—ì„œ ê´€ë ¨ ë°ì´í„° ì¡°íšŒ"
    expected: "Employee, Assignment, TimeBucket ë…¸ë“œ ì¡°íšŒ"

  - step: 4
    name: "ëŒ€ì•ˆ ìƒì„±"
    agent: "OptionGenerator"
    expected: "3ì•ˆ ìƒì„± (ë‚´ë¶€ì¬ë°°ì¹˜/ì™¸ë¶€ì¶©ì›/ì—­ëŸ‰ê°•í™”)"

  - step: 5
    name: "ì˜í–¥ë„ ì‹œë®¬ë ˆì´ì…˜"
    agent: "ImpactSimulator"
    expected: "As-Is vs To-Be ë¹„êµ ê²°ê³¼"

  - step: 6
    name: "ì„±ê³µí™•ë¥  ê³„ì‚°"
    agent: "SuccessProbability"
    expected: "ê° ì˜µì…˜ë³„ ì„±ê³µí™•ë¥ "

  - step: 7
    name: "ê²€ì¦"
    agent: "Validator"
    expected: "ê·¼ê±° ì—°ê²°ë¥  > 95%, í™˜ê°ë¥  < 5%"

  - step: 8
    name: "HITL ìŠ¹ì¸"
    action: "ìŠ¹ì¸ ìš”ì²­ ìƒì„± ë° ì²˜ë¦¬"
    expected: "ìŠ¹ì¸ ì™„ë£Œ"

  - step: 9
    name: "ì›Œí¬í”Œë¡œ ìƒì„±"
    agent: "WorkflowBuilder"
    expected: "ì‹¤í–‰ ê³„íš ìƒì„±"

acceptance:
  - "AC-1: ìœ ìŠ¤ì¼€ì´ìŠ¤ ì‘ë‹µ âœ“"
  - "AC-2: 3ì•ˆ ë¹„êµ âœ“"
  - "AC-3: ê·¼ê±° ì—°ê²°ë¥  â‰¥ 95% âœ“"
  - "AC-4: í™˜ê°ë¥  â‰¤ 5% âœ“"
  - "AC-6: HITL ì›Œí¬í”Œë¡œ âœ“"
```

### 7.2 E2E ì‹œë‚˜ë¦¬ì˜¤: B-1 ì§ˆë¬¸ ì „ì²´ í”Œë¡œìš°

```yaml
scenario_id: E2E-02
name: "B-1 ì§ˆë¬¸ ì „ì²´ í”Œë¡œìš°"
category: E2E
priority: P0

steps:
  - step: 1
    input: "'100ì–µ ë¯¸ë””ì–´ AX' í”„ë¡œì íŠ¸ ë‚´ë¶€ ìˆ˜í–‰ ê°€ëŠ¥ ì—¬ë¶€ì™€ ì„±ê³µí™•ë¥ "

  - step: 2
    expected: "GO_NOGO íƒ€ì…ìœ¼ë¡œ ë¶„í•´"

  - step: 3
    expected: "Opportunity, ResourceDemand, Competency ë…¸ë“œ ì¡°íšŒ"

  - step: 4
    expected: "3ì•ˆ ìƒì„± (100%ë‚´ë¶€/ë‚´ë¶€70%+ì™¸ë¶€30%/ì—­ëŸ‰ê°•í™”í›„ìˆ˜ì£¼)"

  - step: 5
    expected: "ë§ˆì§„ìœ¨, ë¦¬ìŠ¤í¬ ë ˆë²¨ ë¹„êµ"

  - step: 6
    expected: "ì„±ê³µí™•ë¥  0.45/0.75/0.65"

  - step: 7
    expected: "ê·¼ê±° ì—°ê²° í™•ì¸"

  - step: 8
    expected: "10ì–µ ì´ìƒ â†’ EXECUTIVE ìŠ¹ì¸"
```

---

## 8. í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³  í…œí”Œë¦¿

### 8.1 ì¼ì¼ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸

```markdown
# Daily Test Report - Day X (YYYY-MM-DD)

## ìš”ì•½
- ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: XXê°œ
- Pass: XXê°œ (XX%)
- Fail: XXê°œ (XX%)
- Skip: XXê°œ

## ìƒì„¸ ê²°ê³¼

### Unit Tests
| ëª¨ë“ˆ | Pass | Fail | Coverage |
|------|------|------|----------|
| query_decomposition | X/X | X | XX% |
| option_generator | X/X | X | XX% |
| ... | | | |

### Integration Tests
| ì‹œë‚˜ë¦¬ì˜¤ | ê²°ê³¼ | ë¹„ê³  |
|----------|------|------|
| TS-DX-01 | âœ…/âŒ | |

### Acceptance Criteria
| AC | ëª©í‘œ | í˜„ì¬ | ìƒíƒœ |
|----|------|------|------|
| AC-1 | 100% | XX% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| AC-2 | 100% | XX% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| AC-3 | â‰¥95% | XX% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| AC-4 | â‰¤5% | XX% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| AC-5 | 100% | XX% | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
| AC-6 | ë™ì‘ | Y/N | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |

## ì´ìŠˆ
1. [Issue ì œëª©] - ì‹¬ê°ë„, ë‹´ë‹¹ì, ì˜ˆìƒ í•´ê²°ì¼
```

### 8.2 pytest ì‹¤í–‰ ëª…ë ¹

```bash
# Day ë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/test_day2_data_readiness.py -v --tb=short
pytest tests/test_day3_kg.py -v --tb=short
pytest tests/test_day4_agents.py -v --tb=short
pytest tests/test_day5_workflow.py -v --tb=short

# ì „ì²´ í…ŒìŠ¤íŠ¸ + ì»¤ë²„ë¦¬ì§€
pytest tests/ -v --cov=backend --cov-report=html

# íŠ¹ì • ë§ˆì»¤ë¡œ í•„í„°
pytest -m "acceptance" -v  # AC í…ŒìŠ¤íŠ¸ë§Œ
pytest -m "e2e" -v         # E2E í…ŒìŠ¤íŠ¸ë§Œ
```

---

## ë¶€ë¡: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…‹

### A. Mock Input ë°ì´í„°

```json
{
  "test_questions": {
    "A-1": "í–¥í›„ 12ì£¼ê°„ ë³¸ë¶€/íŒ€ë³„ ê°€ë™ë¥  90% ì´ˆê³¼ ì£¼ì°¨ì™€ ë³‘ëª© ì›ì¸ì„ ì˜ˆì¸¡í•´ì¤˜",
    "B-1": "'100ì–µ ë¯¸ë””ì–´ AX' í”„ë¡œì íŠ¸ë¥¼ ë‚´ë¶€ ìˆ˜í–‰ ê°€ëŠ¥í•œì§€, ì„±ê³µí™•ë¥ ì€ ì–¼ë§ˆì¸ì§€ ì•Œë ¤ì¤˜",
    "C-1": "ë°ì´í„°í”Œë«í¼íŒ€ 1ëª… ì¦ì› ìš”ì²­ì˜ ì›ì¸ì„ ë¶„í•´í•´ì¤˜",
    "D-1": "AI-driven ì „í™˜ ê´€ì ì—ì„œ ì—­ëŸ‰ ê°­ Top10ì„ ì •ëŸ‰í™”í•´ì¤˜"
  }
}
```

### B. Expected Output ìƒ˜í”Œ

```json
{
  "A-1_expected": {
    "type": "CAPACITY_FORECAST",
    "options_count": 3,
    "findings_min": 1,
    "evidence_required": true
  }
}
```

---

*ì´ ë¬¸ì„œëŠ” PoC ì§„í–‰ ì¤‘ ì—…ë°ì´íŠ¸ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*
